#!/usr/bin/env python3
"""
FastAPI ê¸°ë°˜ ì´ë¯¸ì§€ ì„ë² ë”© ìœ ì‚¬ë„ API ì„œë²„
MediaPipeë¥¼ ì‚¬ìš©í•œ ì´ë¯¸ì§€ ì„ë² ë”© ë° ìœ ì‚¬ë„ ê³„ì‚°
"""

import os
import math
import tempfile
import shutil
from pathlib import Path
from typing import List, Optional, Dict, Any
from contextlib import asynccontextmanager

import cv2
import numpy as np
import mediapipe as mp
from mediapipe.tasks import python
from mediapipe.tasks.python import vision

# FastAPI ë° ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬
from fastapi import FastAPI, HTTPException, UploadFile, File, Form, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field
import uvicorn

# ë¡œê¹… ì„¤ì •
import logging
logging.getLogger().setLevel(logging.ERROR)

# ====== ì„¤ì • ======
DESIRED_HEIGHT = 480
DESIRED_WIDTH = 480
IMG_EXTS = {".jpg", ".jpeg", ".png", ".bmp", ".webp"}
ALLOWED_EXTENSIONS = IMG_EXTS

# ìë™ ëª¨ë¸ ê²½ë¡œ(í™˜ê²½ë³€ìˆ˜ ìš°ì„ )
AUTO_MODEL_PATH = os.getenv("IMAGE_EMBEDDER_PATH", "models/mobilenet_v3_small.tflite")

# ì „ì—­ ìƒíƒœ
embedder = None
model_path: Optional[Path] = None

# ====== Pydantic ëª¨ë¸ ======
class ImageSimilarityRequest(BaseModel):
    image_paths: List[str] = Field(..., min_items=2, description="ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸")
    l2_normalize: bool = Field(default=True)
    quantize: bool = Field(default=True)

class ImageSimilarityResponse(BaseModel):
    similarity_matrix: List[List[float]]
    image_names: List[str]
    top_pairs: List[Dict[str, Any]]
    total_images: int

class SingleSimilarityRequest(BaseModel):
    image1_path: str
    image2_path: str
    l2_normalize: bool = Field(default=True)
    quantize: bool = Field(default=True)

class SingleSimilarityResponse(BaseModel):
    similarity: float
    image1_name: str
    image2_name: str
    percentage: str

class EmbeddingRequest(BaseModel):
    image_path: str
    l2_normalize: bool = Field(default=True)
    quantize: bool = Field(default=True)

class EmbeddingResponse(BaseModel):
    embedding: List[float]
    image_name: str
    embedding_dim: int

class HealthResponse(BaseModel):
    status: str
    model_loaded: bool
    model_path: Optional[str]
    mediapipe_available: bool

# ====== ìœ í‹¸ ======
def imread_unicode(path: Path) -> Optional[np.ndarray]:
    try:
        data = np.fromfile(str(path), dtype=np.uint8)
        return cv2.imdecode(data, cv2.IMREAD_COLOR)
    except Exception:
        return None

def resize_for_preview(image: np.ndarray) -> np.ndarray:
    h, w = image.shape[:2]
    if h < w:
        new_h = max(1, math.floor(h / (w / DESIRED_WIDTH)))
        return cv2.resize(image, (DESIRED_WIDTH, new_h))
    else:
        new_w = max(1, math.floor(w / (h / DESIRED_HEIGHT)))
        return cv2.resize(image, (new_w, DESIRED_HEIGHT))

def validate_image_path(path: str) -> Path:
    p = Path(path)
    if not p.exists():
        raise HTTPException(status_code=404, detail=f"ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {path}")
    if p.suffix.lower() not in ALLOWED_EXTENSIONS:
        raise HTTPException(status_code=400, detail=f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì´ë¯¸ì§€ í˜•ì‹: {p.suffix}")
    return p

def build_embedder(mpath: Path, l2_normalize: bool = True, quantize: bool = True):
    try:
        base_options = python.BaseOptions(model_asset_path=str(mpath))
        options = vision.ImageEmbedderOptions(
            base_options=base_options, l2_normalize=l2_normalize, quantize=quantize
        )
        return vision.ImageEmbedder.create_from_options(options)
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ì„ë² ë” ìƒì„± ì‹¤íŒ¨: {e}")

def make_mp_image(path: Path) -> mp.Image:
    try:
        return mp.Image.create_from_file(str(path))
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {e}")

def compute_embedding(_embedder, image_path: Path) -> List[float]:
    try:
        mp_image = make_mp_image(image_path)
        result = _embedder.embed(mp_image)
        return result.embeddings[0].embedding
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ì„ë² ë”© ê³„ì‚° ì‹¤íŒ¨: {e}")

def compute_similarities(_embedder, image_paths: List[Path]) -> np.ndarray:
    try:
        mp_images = [make_mp_image(p) for p in image_paths]
        emb_results = [ _embedder.embed(im).embeddings[0] for im in mp_images ]
        n = len(image_paths)
        sims = np.eye(n, dtype=float)
        for i in range(n):
            for j in range(i + 1, n):
                s = vision.ImageEmbedder.cosine_similarity(emb_results[i], emb_results[j])
                sims[i, j] = sims[j, i] = s
        return sims
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ìœ ì‚¬ë„ ê³„ì‚° ì‹¤íŒ¨: {e}")

def get_top_similar_pairs(similarity_matrix: np.ndarray, image_names: List[str], top_k: int = 3) -> List[Dict[str, Any]]:
    pairs = []
    n = len(image_names)
    for i in range(n):
        for j in range(i + 1, n):
            pairs.append({
                "image1_index": i,
                "image2_index": j,
                "image1_name": image_names[i],
                "image2_name": image_names[j],
                "similarity": float(similarity_matrix[i, j])
            })
    pairs.sort(key=lambda x: x["similarity"], reverse=True)
    return pairs[:top_k]

# ====== ì•± ë¼ì´í”„ì‚¬ì´í´ ======
@asynccontextmanager
async def lifespan(app: FastAPI):
    global embedder, model_path
    print("ğŸš€ ì´ë¯¸ì§€ ì„ë² ë”© API ì„œë²„ ì‹œì‘")
    print(f"ğŸ“ MediaPipe ì‚¬ìš© ê°€ëŠ¥: {mp is not None}")
    # ìë™ ëª¨ë¸ ë¡œë“œ
    try:
        cand = Path(AUTO_MODEL_PATH)
        if cand.exists():
            embedder = build_embedder(cand, l2_normalize=True, quantize=True)
            model_path = cand
            print(f"âœ… ìë™ ëª¨ë¸ ë¡œë“œ: {cand}")
        else:
            print(f"â„¹ï¸ ìë™ ëª¨ë¸ ë¡œë“œ ìƒëµ(íŒŒì¼ ì—†ìŒ): {cand}")
    except Exception as e:
        print(f"âš ï¸ ìë™ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
    yield
    print("ğŸ›‘ ì´ë¯¸ì§€ ì„ë² ë”© API ì„œë²„ ì¢…ë£Œ")

# ====== FastAPI ì•± ======
app = FastAPI(
    title="Image Embedding Similarity API",
    description="MediaPipeë¥¼ ì‚¬ìš©í•œ ì´ë¯¸ì§€ ì„ë² ë”© ë° ìœ ì‚¬ë„ ê³„ì‚° API",
    version="1.1.0",
    lifespan=lifespan
)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"], allow_credentials=True,
    allow_methods=["*"], allow_headers=["*"],
)

# ====== ì—”ë“œí¬ì¸íŠ¸ ======
@app.get("/", response_model=Dict[str, str])
async def root():
    return {"message": "Image Embedding Similarity API", "version": "1.1.0", "docs": "/docs", "health": "/health"}

@app.get("/health", response_model=HealthResponse)
async def health_check():
    return HealthResponse(
        status="healthy",
        model_loaded=embedder is not None,
        model_path=str(model_path) if model_path else None,
        mediapipe_available=mp is not None
    )

@app.post("/load-model")
async def load_model(
    model_path_str: str = Form(..., description="TFLite ëª¨ë¸ íŒŒì¼ ê²½ë¡œ"),
    l2_normalize: bool = Form(default=True),
    quantize: bool = Form(default=True)
):
    global embedder, model_path
    mpath = Path(model_path_str)
    if not mpath.exists():
        raise HTTPException(status_code=404, detail=f"ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path_str}")
    embedder = build_embedder(mpath, l2_normalize, quantize)
    model_path = mpath
    return {"message": "ëª¨ë¸ ë¡œë“œ ì„±ê³µ", "model_path": str(mpath), "l2_normalize": l2_normalize, "quantize": quantize}

@app.post("/embedding", response_model=EmbeddingResponse)
async def get_embedding(req: EmbeddingRequest):
    if embedder is None:
        raise HTTPException(status_code=400, detail="ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. /load-modelì„ ë¨¼ì € í˜¸ì¶œí•˜ì„¸ìš”.")
    image_path = validate_image_path(req.image_path)
    vec = compute_embedding(embedder, image_path)
    return EmbeddingResponse(embedding=vec, image_name=image_path.name, embedding_dim=len(vec))

@app.post("/similarity/single", response_model=SingleSimilarityResponse)
async def compute_single_similarity(req: SingleSimilarityRequest):
    if embedder is None:
        raise HTTPException(status_code=400, detail="ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. /load-modelì„ ë¨¼ì € í˜¸ì¶œí•˜ì„¸ìš”.")
    p1 = validate_image_path(req.image1_path)
    p2 = validate_image_path(req.image2_path)
    emb1 = compute_embedding(embedder, p1)
    emb2 = compute_embedding(embedder, p2)
    sim = vision.ImageEmbedder.cosine_similarity(
        vision.Embedding(embedding=emb1), vision.Embedding(embedding=emb2)
    )
    return SingleSimilarityResponse(
        similarity=float(sim), image1_name=p1.name, image2_name=p2.name, percentage=f"{sim*100:.1f}%"
    )

@app.post("/similarity/batch", response_model=ImageSimilarityResponse)
async def compute_batch_similarity(req: ImageSimilarityRequest):
    if embedder is None:
        raise HTTPException(status_code=400, detail="ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. /load-modelì„ ë¨¼ì € í˜¸ì¶œí•˜ì„¸ìš”.")
    paths = [validate_image_path(p) for p in req.image_paths]
    sims = compute_similarities(embedder, paths)
    names = [p.name for p in paths]
    top_pairs = get_top_similar_pairs(sims, names)
    return ImageSimilarityResponse(similarity_matrix=sims.tolist(), image_names=names, top_pairs=top_pairs, total_images=len(paths))

# ---- ì—…ë¡œë“œ: keep_temp ì§€ì› ì¶”ê°€ ----
@app.post("/upload-images")
async def upload_images(
    files: List[UploadFile] = File(..., description="ì—…ë¡œë“œí•  ì´ë¯¸ì§€ íŒŒì¼ë“¤"),
    keep_temp: bool = Form(False),
    background_tasks: BackgroundTasks = None
):
    if not files:
        raise HTTPException(status_code=400, detail="ì—…ë¡œë“œí•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    for f in files:
        if not any(f.filename.lower().endswith(ext) for ext in ALLOWED_EXTENSIONS):
            raise HTTPException(status_code=400, detail=f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: {f.filename}")

    temp_dir = Path(tempfile.mkdtemp())
    saved_paths: List[str] = []
    try:
        for f in files:
            fp = temp_dir / f.filename
            with open(fp, "wb") as buf:
                shutil.copyfileobj(f.file, buf)
            saved_paths.append(str(fp))
        # ê¸°ë³¸ì€ ì‚­ì œ, keep_tempë©´ ìœ ì§€
        if background_tasks and not keep_temp:
            background_tasks.add_task(shutil.rmtree, temp_dir)
        return {
            "message": f"{len(files)}ê°œ íŒŒì¼ ì—…ë¡œë“œ ì„±ê³µ",
            "saved_paths": saved_paths,
            "temp_directory": str(temp_dir),
            "kept": bool(keep_temp)
        }
    except Exception as e:
        shutil.rmtree(temp_dir, ignore_errors=True)
        raise HTTPException(status_code=500, detail=f"íŒŒì¼ ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")

# ---- ì›ìŠ¤í…: ì—…ë¡œë“œ + ì¦‰ì‹œ ìœ ì‚¬ë„ ----
@app.post("/similarity/upload-single", response_model=SingleSimilarityResponse)
async def upload_and_compare_single(
    file1: UploadFile = File(..., description="ì²« ë²ˆì§¸ ì´ë¯¸ì§€ íŒŒì¼"),
    file2: UploadFile = File(..., description="ë‘ ë²ˆì§¸ ì´ë¯¸ì§€ íŒŒì¼"),
    l2_normalize: bool = Form(default=True),
    quantize: bool = Form(default=True)
):
    if embedder is None:
        raise HTTPException(status_code=400, detail="ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. /load-modelì„ ë¨¼ì € í˜¸ì¶œí•˜ì„¸ìš”.")
    tmp_dir = Path(tempfile.mkdtemp())
    try:
        p1 = tmp_dir / file1.filename
        p2 = tmp_dir / file2.filename
        with open(p1, "wb") as b1: shutil.copyfileobj(file1.file, b1)
        with open(p2, "wb") as b2: shutil.copyfileobj(file2.file, b2)
        # (ì˜µì…˜ í”Œë˜ê·¸ëŠ” embedder ìƒì„± ì‹œ ë°˜ì˜ë˜ë¯€ë¡œ ì—¬ê¸°ì„  ì •ë³´ë¡œë§Œ)
        e1 = compute_embedding(embedder, p1)
        e2 = compute_embedding(embedder, p2)
        sim = vision.ImageEmbedder.cosine_similarity(
            vision.Embedding(embedding=e1), vision.Embedding(embedding=e2)
        )
        return SingleSimilarityResponse(
            similarity=float(sim), image1_name=p1.name, image2_name=p2.name, percentage=f"{sim*100:.1f}%"
        )
    finally:
        shutil.rmtree(tmp_dir, ignore_errors=True)

@app.post("/similarity/upload-batch", response_model=ImageSimilarityResponse)
async def upload_and_compare_batch(
    files: List[UploadFile] = File(..., description="ì—¬ëŸ¬ ì´ë¯¸ì§€ íŒŒì¼"),
):
    if embedder is None:
        raise HTTPException(status_code=400, detail="ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. /load-modelì„ ë¨¼ì € í˜¸ì¶œí•˜ì„¸ìš”.")
    if len(files) < 2:
        raise HTTPException(status_code=400, detail="ìµœì†Œ 2ê°œ ì´ìƒì˜ íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤.")
    tmp_dir = Path(tempfile.mkdtemp())
    try:
        paths: List[Path] = []
        for f in files:
            if not any(f.filename.lower().endswith(ext) for ext in ALLOWED_EXTENSIONS):
                raise HTTPException(status_code=400, detail=f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: {f.filename}")
            p = tmp_dir / f.filename
            with open(p, "wb") as b: shutil.copyfileobj(f.file, b)
            paths.append(p)
        sims = compute_similarities(embedder, paths)
        names = [p.name for p in paths]
        top_pairs = get_top_similar_pairs(sims, names)
        return ImageSimilarityResponse(
            similarity_matrix=sims.tolist(), image_names=names, top_pairs=top_pairs, total_images=len(paths)
        )
    finally:
        shutil.rmtree(tmp_dir, ignore_errors=True)

if __name__ == "__main__":
    uvicorn.run(
        "image_embedding_api:app",
        host="0.0.0.0",
        port=8001,
        reload=True,
        log_level="info"
    )
